{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17209d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 13:45:20,288 INFO: Closing external client and cleaning up certificates.\n",
      "2026-01-11 13:45:20,295 INFO: Connection closed.\n",
      "2026-01-11 13:45:20,296 INFO: Initializing external client\n",
      "2026-01-11 13:45:20,297 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-11 13:45:20,970 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/3209\n",
      "[OK] Feature group exists: traffic_temporal_prepared_fg v1\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.01s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'insert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 78\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mtraffic_prepared_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m(read_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_hive\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SKIP] traffic_prepared_fg already has data (not re-inserting).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m     traffic_df \u001b[38;5;241m=\u001b[39m read_fg_as_df(traffic_fg)\n\u001b[1;32m     82\u001b[0m     traffic_df \u001b[38;5;241m=\u001b[39m make_ts_1h(traffic_df, source_time_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mts_10m\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mts_1h\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m     \u001b[43minsert_fg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraffic_prepared_fg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraffic_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# 4) Prepare LABELS (10-min) -> add ts_1h (optional but handy)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#    Labels join to traffic on (point_id, ts_10m)\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n\u001b[1;32m     89\u001b[0m labels_prepared_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_speed_ratio_prepared_fg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 58\u001b[0m, in \u001b[0;36minsert_fg\u001b[0;34m(fg, df)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minsert_fg\u001b[39m(fg, df):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Remove pandas index to avoid accidental columns\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m(df, write_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INSERTED] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfg\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfg\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'insert'"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "\n",
    "# =========================================================\n",
    "# 0) Login\n",
    "# =========================================================\n",
    "project = hopsworks.login(\n",
    "    host=\"eu-west.cloud.hopsworks.ai\",\n",
    "    project=\"London_traffic\"\n",
    ")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# =========================================================\n",
    "# 1) Load original feature groups\n",
    "# =========================================================\n",
    "traffic_fg = fs.get_feature_group(name=\"traffic_temporal_fg\", version=1)\n",
    "weather_fg = fs.get_feature_group(name=\"weather_hourly_fg\", version=1)\n",
    "tfl_fg     = fs.get_feature_group(name=\"tfl_disruptions_hourly_fg\", version=1)\n",
    "labels_fg  = fs.get_feature_group(name=\"labels_speed_ratio_fg\", version=1)\n",
    "\n",
    "# =========================================================\n",
    "# 2) Helper functions\n",
    "# =========================================================\n",
    "def read_fg_as_df(fg):\n",
    "    # Using Hive is usually the safest for batch reads\n",
    "    return fg.read(read_options={\"use_hive\": True})\n",
    "\n",
    "def ensure_utc_timestamp(df, col):\n",
    "    # Make sure timestamps are pandas datetime\n",
    "    df[col] = pd.to_datetime(df[col], utc=True, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def make_ts_1h(df, source_time_col, new_col=\"ts_1h\"):\n",
    "    df = ensure_utc_timestamp(df, source_time_col)\n",
    "    df[new_col] = df[source_time_col].dt.floor(\"H\")\n",
    "    return df\n",
    "\n",
    "def get_or_create_fg(name, version, primary_key, event_time, description):\n",
    "    try:\n",
    "        fg = fs.get_feature_group(name=name, version=version)\n",
    "        print(f\"[OK] Feature group exists: {name} v{version}\")\n",
    "        return fg\n",
    "    except Exception:\n",
    "        fg = fs.create_feature_group(\n",
    "            name=name,\n",
    "            version=version,\n",
    "            primary_key=primary_key,\n",
    "            event_time=event_time,\n",
    "            description=description,\n",
    "            online_enabled=False\n",
    "        )\n",
    "        print(f\"[CREATED] Feature group: {name} v{version}\")\n",
    "        return fg\n",
    "\n",
    "def insert_fg(fg, df):\n",
    "    # Remove pandas index to avoid accidental columns\n",
    "    df = df.reset_index(drop=True)\n",
    "    fg.insert(df, write_options={\"wait_for_job\": True})\n",
    "    print(f\"[INSERTED] {fg.name} v{fg.version} rows={len(df)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 3) Prepare TRAFFIC (10-min) -> add ts_1h\n",
    "#    Keep ts_10m as event_time + join labels on (point_id, ts_10m)\n",
    "# =========================================================\n",
    "traffic_prepared_name = \"traffic_temporal_prepared_fg\"\n",
    "traffic_prepared_ver  = 1\n",
    "\n",
    "traffic_prepared_fg = get_or_create_fg(\n",
    "    name=traffic_prepared_name,\n",
    "    version=traffic_prepared_ver,\n",
    "    primary_key=[\"point_id\", \"ts_10m\"],\n",
    "    event_time=\"ts_10m\",\n",
    "    description=\"Prepared traffic FG: adds ts_1h = floor(ts_10m) for hourly joins.\"\n",
    ")\n",
    "\n",
    "# Only backfill/insert if empty or newly created\n",
    "try:\n",
    "    _ = traffic_prepared_fg.read(read_options={\"use_hive\": True}).head(1)\n",
    "    print(\"[SKIP] traffic_prepared_fg already has data (not re-inserting).\")\n",
    "except Exception:\n",
    "    traffic_df = read_fg_as_df(traffic_fg)\n",
    "    traffic_df = make_ts_1h(traffic_df, source_time_col=\"ts_10m\", new_col=\"ts_1h\")\n",
    "    insert_fg(traffic_prepared_fg, traffic_df)\n",
    "\n",
    "# =========================================================\n",
    "# 4) Prepare LABELS (10-min) -> add ts_1h (optional but handy)\n",
    "#    Labels join to traffic on (point_id, ts_10m)\n",
    "# =========================================================\n",
    "labels_prepared_name = \"labels_speed_ratio_prepared_fg\"\n",
    "labels_prepared_ver  = 1\n",
    "\n",
    "labels_prepared_fg = get_or_create_fg(\n",
    "    name=labels_prepared_name,\n",
    "    version=labels_prepared_ver,\n",
    "    primary_key=[\"point_id\", \"ts_10m\"],\n",
    "    event_time=\"ts_10m\",\n",
    "    description=\"Prepared labels FG: keeps 10-min keys and adds ts_1h for alignment/debug.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    _ = labels_prepared_fg.read(read_options={\"use_hive\": True}).head(1)\n",
    "    print(\"[SKIP] labels_prepared_fg already has data (not re-inserting).\")\n",
    "except Exception:\n",
    "    labels_df = read_fg_as_df(labels_fg)\n",
    "    labels_df = make_ts_1h(labels_df, source_time_col=\"ts_10m\", new_col=\"ts_1h\")\n",
    "    insert_fg(labels_prepared_fg, labels_df)\n",
    "\n",
    "# =========================================================\n",
    "# 5) Prepare WEATHER (hourly) -> rename weather_time_utc -> ts_1h\n",
    "#    Join on (point_id, ts_1h)\n",
    "# =========================================================\n",
    "weather_prepared_name = \"weather_hourly_prepared_fg\"\n",
    "weather_prepared_ver  = 1\n",
    "\n",
    "weather_prepared_fg = get_or_create_fg(\n",
    "    name=weather_prepared_name,\n",
    "    version=weather_prepared_ver,\n",
    "    primary_key=[\"point_id\", \"ts_1h\"],\n",
    "    event_time=\"ts_1h\",\n",
    "    description=\"Prepared weather FG: renames weather_time_utc to ts_1h for joins.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    _ = weather_prepared_fg.read(read_options={\"use_hive\": True}).head(1)\n",
    "    print(\"[SKIP] weather_prepared_fg already has data (not re-inserting).\")\n",
    "except Exception:\n",
    "    weather_df = read_fg_as_df(weather_fg)\n",
    "    weather_df = ensure_utc_timestamp(weather_df, \"weather_time_utc\")\n",
    "    weather_df = weather_df.rename(columns={\"weather_time_utc\": \"ts_1h\"})\n",
    "    insert_fg(weather_prepared_fg, weather_df)\n",
    "\n",
    "# =========================================================\n",
    "# 6) Prepare TFL (hourly) -> rename tfl_time_utc -> ts_1h\n",
    "#    Join on (point_id, ts_1h)\n",
    "# =========================================================\n",
    "tfl_prepared_name = \"tfl_disruptions_hourly_prepared_fg\"\n",
    "tfl_prepared_ver  = 1\n",
    "\n",
    "tfl_prepared_fg = get_or_create_fg(\n",
    "    name=tfl_prepared_name,\n",
    "    version=tfl_prepared_ver,\n",
    "    primary_key=[\"point_id\", \"ts_1h\"],\n",
    "    event_time=\"ts_1h\",\n",
    "    description=\"Prepared TfL disruptions FG: renames tfl_time_utc to ts_1h for joins.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    _ = tfl_prepared_fg.read(read_options={\"use_hive\": True}).head(1)\n",
    "    print(\"[SKIP] tfl_prepared_fg already has data (not re-inserting).\")\n",
    "except Exception:\n",
    "    tfl_df = read_fg_as_df(tfl_fg)\n",
    "    tfl_df = ensure_utc_timestamp(tfl_df, \"tfl_time_utc\")\n",
    "    tfl_df = tfl_df.rename(columns={\"tfl_time_utc\": \"ts_1h\"})\n",
    "    insert_fg(tfl_prepared_fg, tfl_df)\n",
    "\n",
    "# =========================================================\n",
    "# 7) Create Feature View\n",
    "#    - Join traffic + labels on (point_id, ts_10m)\n",
    "#    - Join weather + tfl on (point_id, ts_1h)\n",
    "# =========================================================\n",
    "LABEL_COLS = [\"label_speed_ratio_t_plus_30\", \"label_speed_ratio_t_plus_60\"]\n",
    "\n",
    "traffic_p = fs.get_feature_group(name=traffic_prepared_name, version=traffic_prepared_ver)\n",
    "labels_p  = fs.get_feature_group(name=labels_prepared_name, version=labels_prepared_ver)\n",
    "weather_p = fs.get_feature_group(name=weather_prepared_name, version=weather_prepared_ver)\n",
    "tfl_p     = fs.get_feature_group(name=tfl_prepared_name, version=tfl_prepared_ver)\n",
    "\n",
    "# Build query:\n",
    "# 1) start with traffic (10-min)\n",
    "# 2) add labels (10-min exact match)\n",
    "# 3) add weather + tfl using hourly key already inside traffic (ts_1h)\n",
    "q = (\n",
    "    traffic_p.select_all()\n",
    "    .join(labels_p.select([\"point_id\", \"ts_10m\"] + LABEL_COLS), on=[\"point_id\", \"ts_10m\"])\n",
    "    .join(weather_p.select_all(), on=[\"point_id\", \"ts_1h\"])\n",
    "    .join(tfl_p.select_all(), on=[\"point_id\", \"ts_1h\"])\n",
    ")\n",
    "\n",
    "FV_NAME = \"traffic_speed_ratio_fv\"\n",
    "FV_VERSION = 1\n",
    "\n",
    "# Create or load FV\n",
    "try:\n",
    "    fv = fs.get_feature_view(name=FV_NAME, version=FV_VERSION)\n",
    "    print(f\"[OK] Feature view already exists: {FV_NAME} v{FV_VERSION}\")\n",
    "except Exception:\n",
    "    fv = fs.create_feature_view(\n",
    "        name=FV_NAME,\n",
    "        version=FV_VERSION,\n",
    "        query=q,\n",
    "        labels=LABEL_COLS,\n",
    "        description=(\n",
    "            \"Training FV: traffic (10-min) + labels (t+30,t+60) joined on (point_id, ts_10m) \"\n",
    "            \"+ weather hourly + TfL hourly joined on (point_id, ts_1h).\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"[CREATED] Feature view: {FV_NAME} v{FV_VERSION}\")\n",
    "\n",
    "# =========================================================\n",
    "# 8) Quick sanity check (small sample)\n",
    "# =========================================================\n",
    "df_preview = fv.get_batch_data(read_options={\"use_hive\": True})\n",
    "print(\"FV shape:\", df_preview.shape)\n",
    "print(\"Columns sample:\", df_preview.columns.tolist()[:40])\n",
    "df_preview.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
