{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7600a950",
   "metadata": {},
   "source": [
    "# 08_sanity_check_feature_groups.ipynb\n",
    "\n",
    "Sanity checks across Feature Groups before label engineering:\n",
    "- Traffic temporal FG (lags/rollings/time features)\n",
    "- Weather hourly FG (Open-Meteo)\n",
    "- TfL disruptions hourly FG\n",
    "\n",
    "This notebook reads only (no writes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c9695ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc69a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= CONFIG =================\n",
    "TRAFFIC_FG_NAME = os.getenv(\"TRAFFIC_FG_NAME\", \"traffic_temporal_fg\")\n",
    "TRAFFIC_FG_VERSION = int(os.getenv(\"TRAFFIC_FG_VERSION\", \"1\"))\n",
    "\n",
    "WEATHER_FG_NAME = os.getenv(\"WEATHER_FG_NAME\", \"weather_hourly_fg\")\n",
    "WEATHER_FG_VERSION = int(os.getenv(\"WEATHER_FG_VERSION\", \"1\"))\n",
    "\n",
    "TFL_FG_NAME = os.getenv(\"TFL_FG_NAME\", \"tfl_disruptions_hourly_fg\")\n",
    "TFL_FG_VERSION = int(os.getenv(\"TFL_FG_VERSION\", \"1\"))\n",
    "\n",
    "TRAFFIC_TIME_COL = os.getenv(\"TRAFFIC_TIME_COL\", \"ts_10m\")\n",
    "WEATHER_TIME_COL = os.getenv(\"WEATHER_TIME_COL\", \"weather_time_utc\")\n",
    "TFL_TIME_COL = os.getenv(\"TFL_TIME_COL\", \"tfl_time_utc\")\n",
    "\n",
    "POINT_ID_COL = os.getenv(\"POINT_ID_COL\", \"point_id\")\n",
    "\n",
    "# Optional: comma-separated list of expected lag/rolling columns (strict check)\n",
    "EXPECTED_LAG_COLS = os.getenv(\"EXPECTED_LAG_COLS\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3904d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-09 14:26:03,057 INFO: Initializing external client\n",
      "2026-01-09 14:26:03,059 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-09 14:26:03,962 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/3209\n"
     ]
    }
   ],
   "source": [
    "# ============== CONNECT TO HOPSWORKS ==============\n",
    "project = hopsworks.login(\n",
    "    host=\"eu-west.cloud.hopsworks.ai\",\n",
    "    project=\"London_traffic\"\n",
    ")\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23adbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_profile(df: pd.DataFrame, name: str, time_col: str, pk_cols: list):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"PROFILE: {name}\")\n",
    "    print(\"=\"*90)\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(\"n_columns:\", len(df.columns))\n",
    "\n",
    "    # dtypes sample\n",
    "    print(\"\\nDtypes (first 30):\")\n",
    "    print(df.dtypes.head(30))\n",
    "\n",
    "    # time range\n",
    "    if time_col in df.columns:\n",
    "        t = pd.to_datetime(df[time_col], utc=True, errors=\"coerce\")\n",
    "        print(f\"\\nTime column: {time_col}\")\n",
    "        print(\"time_min:\", t.min())\n",
    "        print(\"time_max:\", t.max())\n",
    "        print(\"time_nulls:\", t.isna().sum())\n",
    "    else:\n",
    "        print(f\"\\nTime column missing: {time_col}\")\n",
    "\n",
    "    # PK duplicates\n",
    "    missing_pk = [c for c in pk_cols if c not in df.columns]\n",
    "    if missing_pk:\n",
    "        print(\"\\nMissing PK columns:\", missing_pk)\n",
    "    else:\n",
    "        dup = df.duplicated(subset=pk_cols).sum()\n",
    "        print(\"\\nPK columns:\", pk_cols)\n",
    "        print(\"PK duplicate rows:\", dup)\n",
    "\n",
    "    # Missingness summary (top 20)\n",
    "    na = df.isna().mean().sort_values(ascending=False)\n",
    "    print(\"\\nTop missingness (fraction):\")\n",
    "    print(na.head(20))\n",
    "\n",
    "def assert_no_pk_dups(df: pd.DataFrame, pk_cols: list, name: str):\n",
    "    if all(c in df.columns for c in pk_cols):\n",
    "        dup = df.duplicated(subset=pk_cols).sum()\n",
    "        if dup > 0:\n",
    "            raise ValueError(f\"{name}: found {dup} duplicate rows for PK {pk_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c593a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.71s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.52s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.54s) \n"
     ]
    }
   ],
   "source": [
    "# ============== READ FEATURE GROUPS ==============\n",
    "traffic_fg = fs.get_feature_group(name=TRAFFIC_FG_NAME, version=TRAFFIC_FG_VERSION)\n",
    "weather_fg = fs.get_feature_group(name=WEATHER_FG_NAME, version=WEATHER_FG_VERSION)\n",
    "tfl_fg = fs.get_feature_group(name=TFL_FG_NAME, version=TFL_FG_VERSION)\n",
    "\n",
    "traffic_df = traffic_fg.read()\n",
    "weather_df = weather_fg.read()\n",
    "tfl_df = tfl_fg.read()\n",
    "\n",
    "# Normalize types\n",
    "traffic_df[POINT_ID_COL] = traffic_df[POINT_ID_COL].astype(str)\n",
    "weather_df[POINT_ID_COL] = weather_df[POINT_ID_COL].astype(str)\n",
    "tfl_df[POINT_ID_COL] = tfl_df[POINT_ID_COL].astype(str)\n",
    "\n",
    "traffic_df[TRAFFIC_TIME_COL] = pd.to_datetime(traffic_df[TRAFFIC_TIME_COL], utc=True, errors=\"coerce\")\n",
    "weather_df[WEATHER_TIME_COL] = pd.to_datetime(weather_df[WEATHER_TIME_COL], utc=True, errors=\"coerce\")\n",
    "tfl_df[TFL_TIME_COL] = pd.to_datetime(tfl_df[TFL_TIME_COL], utc=True, errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7470055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "PROFILE: TRAFFIC traffic_temporal_fg v1\n",
      "==========================================================================================\n",
      "shape: (20168, 33)\n",
      "n_columns: 33\n",
      "\n",
      "Dtypes (first 30):\n",
      "timestamp_utc            datetime64[us, Etc/UTC]\n",
      "point_id                                  object\n",
      "frc                                       object\n",
      "current_speed                            float64\n",
      "free_flow_speed                          float64\n",
      "current_travel_time                      float64\n",
      "free_flow_travel_time                    float64\n",
      "confidence                               float64\n",
      "road_closure                                bool\n",
      "ts_10m                       datetime64[us, UTC]\n",
      "speed_ratio                              float64\n",
      "delay_seconds                            float64\n",
      "day_of_week                                int32\n",
      "is_weekend                                 int64\n",
      "hour                                       int32\n",
      "minute                                     int32\n",
      "is_rush_hour                               int64\n",
      "ti_evening_peak                             bool\n",
      "ti_midday                                   bool\n",
      "ti_morning_peak                             bool\n",
      "ti_night                                    bool\n",
      "speed_diff                               float64\n",
      "travel_time_ratio                        float64\n",
      "low_confidence_flag                        int64\n",
      "speed_roll_mean_3                        float64\n",
      "speed_roll_std_3                         float64\n",
      "delay_roll_mean_3                        float64\n",
      "speed_roll_mean_6                        float64\n",
      "speed_roll_std_6                         float64\n",
      "delay_roll_mean_6                        float64\n",
      "dtype: object\n",
      "\n",
      "Time column: ts_10m\n",
      "time_min: 2026-01-04 21:00:00+00:00\n",
      "time_max: 2026-01-09 13:00:00+00:00\n",
      "time_nulls: 0\n",
      "\n",
      "PK columns: ['point_id', 'ts_10m']\n",
      "PK duplicate rows: 0\n",
      "\n",
      "Top missingness (fraction):\n",
      "timestamp_utc          0.0\n",
      "ti_evening_peak        0.0\n",
      "speed_roll_std_12      0.0\n",
      "speed_roll_mean_12     0.0\n",
      "delay_roll_mean_6      0.0\n",
      "speed_roll_std_6       0.0\n",
      "speed_roll_mean_6      0.0\n",
      "delay_roll_mean_3      0.0\n",
      "speed_roll_std_3       0.0\n",
      "speed_roll_mean_3      0.0\n",
      "low_confidence_flag    0.0\n",
      "travel_time_ratio      0.0\n",
      "speed_diff             0.0\n",
      "ti_night               0.0\n",
      "ti_morning_peak        0.0\n",
      "ti_midday              0.0\n",
      "is_rush_hour           0.0\n",
      "point_id               0.0\n",
      "minute                 0.0\n",
      "hour                   0.0\n",
      "dtype: float64\n",
      "\n",
      "==========================================================================================\n",
      "PROFILE: WEATHER weather_hourly_fg v1\n",
      "==========================================================================================\n",
      "shape: (28800, 9)\n",
      "n_columns: 9\n",
      "\n",
      "Dtypes (first 30):\n",
      "weather_time_utc    datetime64[us, UTC]\n",
      "point_id                         object\n",
      "temperature_2m                  float64\n",
      "precipitation                   float64\n",
      "rain                            float64\n",
      "snowfall                        float64\n",
      "wind_speed_10m                  float64\n",
      "cloud_cover                       int64\n",
      "pressure_msl                    float64\n",
      "dtype: object\n",
      "\n",
      "Time column: weather_time_utc\n",
      "time_min: 2026-01-04 00:00:00+00:00\n",
      "time_max: 2026-01-09 23:00:00+00:00\n",
      "time_nulls: 0\n",
      "\n",
      "PK columns: ['point_id', 'weather_time_utc']\n",
      "PK duplicate rows: 0\n",
      "\n",
      "Top missingness (fraction):\n",
      "weather_time_utc    0.0\n",
      "point_id            0.0\n",
      "temperature_2m      0.0\n",
      "precipitation       0.0\n",
      "rain                0.0\n",
      "snowfall            0.0\n",
      "wind_speed_10m      0.0\n",
      "cloud_cover         0.0\n",
      "pressure_msl        0.0\n",
      "dtype: float64\n",
      "\n",
      "==========================================================================================\n",
      "PROFILE: TFL tfl_disruptions_hourly_fg v1\n",
      "==========================================================================================\n",
      "shape: (61709, 7)\n",
      "n_columns: 7\n",
      "\n",
      "Dtypes (first 30):\n",
      "point_id                         object\n",
      "tfl_time_utc        datetime64[us, UTC]\n",
      "disruption_count                  int64\n",
      "is_works                          int64\n",
      "is_incident                       int64\n",
      "is_active                         int64\n",
      "max_ordinal                       int64\n",
      "dtype: object\n",
      "\n",
      "Time column: tfl_time_utc\n",
      "time_min: 2024-07-08 07:00:00+00:00\n",
      "time_max: 2026-10-07 17:00:00+00:00\n",
      "time_nulls: 0\n",
      "\n",
      "PK columns: ['point_id', 'tfl_time_utc']\n",
      "PK duplicate rows: 0\n",
      "\n",
      "Top missingness (fraction):\n",
      "point_id            0.0\n",
      "tfl_time_utc        0.0\n",
      "disruption_count    0.0\n",
      "is_works            0.0\n",
      "is_incident         0.0\n",
      "is_active           0.0\n",
      "max_ordinal         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============== BASIC PROFILES + PK CHECKS ==============\n",
    "basic_profile(traffic_df, f\"TRAFFIC {TRAFFIC_FG_NAME} v{TRAFFIC_FG_VERSION}\", TRAFFIC_TIME_COL, [POINT_ID_COL, TRAFFIC_TIME_COL])\n",
    "basic_profile(weather_df, f\"WEATHER {WEATHER_FG_NAME} v{WEATHER_FG_VERSION}\", WEATHER_TIME_COL, [POINT_ID_COL, WEATHER_TIME_COL])\n",
    "basic_profile(tfl_df, f\"TFL {TFL_FG_NAME} v{TFL_FG_VERSION}\", TFL_TIME_COL, [POINT_ID_COL, TFL_TIME_COL])\n",
    "\n",
    "assert_no_pk_dups(traffic_df, [POINT_ID_COL, TRAFFIC_TIME_COL], \"traffic\")\n",
    "assert_no_pk_dups(weather_df, [POINT_ID_COL, WEATHER_TIME_COL], \"weather\")\n",
    "assert_no_pk_dups(tfl_df, [POINT_ID_COL, TFL_TIME_COL], \"tfl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86feeae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lag/rolling-like columns found: 10\n",
      "['low_confidence_flag', 'speed_roll_mean_3', 'speed_roll_std_3', 'delay_roll_mean_3', 'speed_roll_mean_6', 'speed_roll_std_6', 'delay_roll_mean_6', 'speed_roll_mean_12', 'speed_roll_std_12', 'delay_roll_mean_12']\n"
     ]
    }
   ],
   "source": [
    "# ============== LAG/ROLLING FEATURES PRESENCE (HEURISTIC) ==============\n",
    "lag_like = [c for c in traffic_df.columns if any(k in c.lower() for k in [\"lag\", \"rolling\", \"roll\", \"ema\", \"ewm\"])]\n",
    "print(\"\\nLag/rolling-like columns found:\", len(lag_like))\n",
    "print(lag_like[:80])\n",
    "\n",
    "if EXPECTED_LAG_COLS.strip():\n",
    "    expected = [x.strip() for x in EXPECTED_LAG_COLS.split(\",\") if x.strip()]\n",
    "    missing = [c for c in expected if c not in traffic_df.columns]\n",
    "    print(\"\\nExpected lag cols:\", len(expected))\n",
    "    print(\"Missing expected lag cols:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8903eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather variables: ['temperature_2m', 'precipitation', 'rain', 'snowfall', 'wind_speed_10m', 'cloud_cover', 'pressure_msl']\n",
      "\n",
      "Weather missingness (fraction):\n",
      "temperature_2m    0.0\n",
      "precipitation     0.0\n",
      "rain              0.0\n",
      "snowfall          0.0\n",
      "wind_speed_10m    0.0\n",
      "cloud_cover       0.0\n",
      "pressure_msl      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============== WEATHER VARS MISSINGNESS ==============\n",
    "weather_vars = [c for c in weather_df.columns if c not in [POINT_ID_COL, WEATHER_TIME_COL]]\n",
    "print(\"\\nWeather variables:\", weather_vars)\n",
    "\n",
    "if weather_vars:\n",
    "    print(\"\\nWeather missingness (fraction):\")\n",
    "    print(weather_df[weather_vars].isna().mean().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c75245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TfL variables: ['disruption_count', 'is_works', 'is_incident', 'is_active', 'max_ordinal']\n",
      "\n",
      "TfL describe (first 30 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disruption_count</th>\n",
       "      <td>61709.0</td>\n",
       "      <td>1.004683</td>\n",
       "      <td>0.070378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_works</th>\n",
       "      <td>61709.0</td>\n",
       "      <td>0.975660</td>\n",
       "      <td>0.154104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_incident</th>\n",
       "      <td>61709.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_active</th>\n",
       "      <td>61709.0</td>\n",
       "      <td>0.754930</td>\n",
       "      <td>0.430132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_ordinal</th>\n",
       "      <td>61709.0</td>\n",
       "      <td>21.060931</td>\n",
       "      <td>32.441720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean        std  min  25%  50%   75%    max\n",
       "disruption_count  61709.0   1.004683   0.070378  1.0  1.0  1.0   1.0    3.0\n",
       "is_works          61709.0   0.975660   0.154104  0.0  1.0  1.0   1.0    1.0\n",
       "is_incident       61709.0   0.000000   0.000000  0.0  0.0  0.0   0.0    0.0\n",
       "is_active         61709.0   0.754930   0.430132  0.0  1.0  1.0   1.0    1.0\n",
       "max_ordinal       61709.0  21.060931  32.441720  3.0  3.0  3.0  24.0  102.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============== TFL VARS DISTRIBUTION ==============\n",
    "tfl_vars = [c for c in tfl_df.columns if c not in [POINT_ID_COL, TFL_TIME_COL]]\n",
    "print(\"\\nTfL variables:\", tfl_vars)\n",
    "\n",
    "if tfl_vars:\n",
    "    print(\"\\nTfL describe (first 30 rows):\")\n",
    "    display(tfl_df[tfl_vars].describe(include=\"all\").transpose().head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac17831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Joined shape: (20168, 47)\n",
      "Weather join coverage (>=1 var present): 1.0\n",
      "TfL join coverage (>=1 var present): 0.10020825069416894\n",
      "\n",
      "Sample join columns:\n",
      "  point_id                    ts_10m          weather_time_utc              tfl_time_utc\n",
      "0    37825 2026-01-05 04:00:00+00:00 2026-01-05 04:00:00+00:00 2026-01-05 04:00:00+00:00\n",
      "1    46818 2026-01-06 06:20:00+00:00 2026-01-06 06:00:00+00:00 2026-01-06 06:00:00+00:00\n",
      "2    17687 2026-01-06 22:40:00+00:00 2026-01-06 22:00:00+00:00 2026-01-06 22:00:00+00:00\n",
      "3    17524 2026-01-07 03:50:00+00:00 2026-01-07 03:00:00+00:00 2026-01-07 03:00:00+00:00\n",
      "4    38572 2026-01-06 10:30:00+00:00 2026-01-06 10:00:00+00:00 2026-01-06 10:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n"
     ]
    }
   ],
   "source": [
    "# ============== JOIN COVERAGE CHECK (TRAFFIC <- WEATHER + TFL) ==============\n",
    "traffic_df[\"weather_time_utc\"] = traffic_df[TRAFFIC_TIME_COL].dt.floor(\"H\")\n",
    "traffic_df[\"tfl_time_utc\"] = traffic_df[TRAFFIC_TIME_COL].dt.floor(\"H\")\n",
    "\n",
    "joined = traffic_df.merge(\n",
    "    weather_df,\n",
    "    left_on=[POINT_ID_COL, \"weather_time_utc\"],\n",
    "    right_on=[POINT_ID_COL, WEATHER_TIME_COL],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_w\"),\n",
    ")\n",
    "\n",
    "joined = joined.merge(\n",
    "    tfl_df,\n",
    "    left_on=[POINT_ID_COL, \"tfl_time_utc\"],\n",
    "    right_on=[POINT_ID_COL, TFL_TIME_COL],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_tfl\"),\n",
    ")\n",
    "\n",
    "print(\"\\nJoined shape:\", joined.shape)\n",
    "\n",
    "# Coverage metrics\n",
    "weather_join_cols = [c for c in weather_vars if c in joined.columns]\n",
    "if weather_join_cols:\n",
    "    weather_cov = 1.0 - joined[weather_join_cols].isna().all(axis=1).mean()\n",
    "    print(\"Weather join coverage (>=1 var present):\", weather_cov)\n",
    "\n",
    "tfl_join_cols = [c for c in tfl_vars if c in joined.columns]\n",
    "if tfl_join_cols:\n",
    "    tfl_cov = 1.0 - joined[tfl_join_cols].isna().all(axis=1).mean()\n",
    "    print(\"TfL join coverage (>=1 var present):\", tfl_cov)\n",
    "\n",
    "print(\"\\nSample join columns:\")\n",
    "print(joined[[POINT_ID_COL, TRAFFIC_TIME_COL, \"weather_time_utc\", \"tfl_time_utc\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6217b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "speed_ratio min/max: 0.08823529411764706 1.0\n",
      "speed_ratio <= 0 count: 0\n",
      "speed_ratio > 2 count: 0\n"
     ]
    }
   ],
   "source": [
    "# ============== QUICK SANITY: SPEED RATIO RANGE ==============\n",
    "if \"speed_ratio\" in joined.columns:\n",
    "    sr = pd.to_numeric(joined[\"speed_ratio\"], errors=\"coerce\")\n",
    "    print(\"\\nspeed_ratio min/max:\", sr.min(), sr.max())\n",
    "    print(\"speed_ratio <= 0 count:\", int((sr <= 0).sum()))\n",
    "    print(\"speed_ratio > 2 count:\", int((sr > 2).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be327ff",
   "metadata": {},
   "source": [
    "## Interpretation guide\n",
    "\n",
    "- PK duplicates should be 0 for all feature groups\n",
    "- Weather join coverage should be high during the weather backfill period\n",
    "- TfL join coverage is naturally sparse, but should not be all-zero if your range includes disruptions\n",
    "- Lag/rolling columns should exist and should not be entirely NaN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
