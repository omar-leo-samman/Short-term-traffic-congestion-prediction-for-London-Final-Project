{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0bfd18b",
   "metadata": {},
   "source": [
    "# 03_weather_feature_backfill.ipynb\n",
    "\n",
    "This notebook performs a **historical backfill** of hourly weather features from **Open-Meteo Historical Weather API** and writes them to a dedicated Hopsworks Feature Group.\n",
    "\n",
    "Why separate?\n",
    "- Weather is external (API), hourly, and reusable across models.\n",
    "- Traffic is 10-min; we will join later using `weather_time_utc = floor(ts_10m, 'H')`.\n",
    "\n",
    "Feature Group (recommended):\n",
    "- Name: `weather_hourly_fg`\n",
    "- Primary key: `[\"point_id\", \"weather_time_utc\"]`\n",
    "- Event time: `\"weather_time_utc\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f971b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Union, Iterable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import hopsworks\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a9d2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= CONFIG =================\n",
    "# Source for date range (traffic FG) - optional but convenient\n",
    "TRAFFIC_FG_NAME = os.getenv(\"TRAFFIC_FG_NAME\", \"traffic_flow_fg\")\n",
    "TRAFFIC_FG_VERSION = int(os.getenv(\"TRAFFIC_FG_VERSION\", \"1\"))\n",
    "\n",
    "# Monitoring points / metadata (must contain point_id + lat/lon)\n",
    "METADATA_FG_NAME = os.getenv(\"METADATA_FG_NAME\", \"traffic_points_metadata\")\n",
    "METADATA_FG_VERSION = int(os.getenv(\"METADATA_FG_VERSION\", \"1\"))\n",
    "\n",
    "# Output weather feature group\n",
    "WEATHER_FG_NAME = os.getenv(\"WEATHER_FG_NAME\", \"weather_hourly_fg\")\n",
    "WEATHER_FG_VERSION = int(os.getenv(\"WEATHER_FG_VERSION\", \"1\"))\n",
    "\n",
    "# Open-Meteo Historical Weather API (archive)\n",
    "ARCHIVE_URL = os.getenv(\"OPEN_METEO_ARCHIVE_URL\", \"https://archive-api.open-meteo.com/v1/archive\")\n",
    "\n",
    "# Hourly variables to request (edit freely)\n",
    "HOURLY_VARS = os.getenv(\n",
    "    \"OPEN_METEO_HOURLY_VARS\",\n",
    "    \"temperature_2m,precipitation,rain,snowfall\"\n",
    ").split(\",\")\n",
    "\n",
    "# Chunk size for multiple locations per request\n",
    "CHUNK_SIZE = int(os.getenv(\"OPEN_METEO_CHUNK_SIZE\", \"50\"))\n",
    "\n",
    "# Politeness / safety\n",
    "SLEEP_SECONDS = float(os.getenv(\"OPEN_METEO_SLEEP_SECONDS\", \"0.2\"))\n",
    "REQUEST_TIMEOUT = int(os.getenv(\"OPEN_METEO_TIMEOUT\", \"60\"))\n",
    "MAX_RETRIES = int(os.getenv(\"OPEN_METEO_MAX_RETRIES\", \"5\"))\n",
    "\n",
    "# Date range override (if set, use these)\n",
    "START_DATE = os.getenv(\"OPEN_METEO_START_DATE\", \"\")  # 'YYYY-MM-DD'\n",
    "END_DATE = os.getenv(\"OPEN_METEO_END_DATE\", \"\")      # 'YYYY-MM-DD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b825d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-10 22:05:10,491 INFO: Closing external client and cleaning up certificates.\n",
      "2026-01-10 22:05:10,538 INFO: Connection closed.\n",
      "2026-01-10 22:05:10,543 INFO: Initializing external client\n",
      "2026-01-10 22:05:10,543 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-10 22:05:11,848 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/3209\n"
     ]
    }
   ],
   "source": [
    "# ============== CONNECT TO HOPSWORKS ==============\n",
    "# 1. Login to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    host=\"eu-west.cloud.hopsworks.ai\",\n",
    "    project=\"London_traffic\"\n",
    ")\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6247decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.49s) \n",
      "Points available for weather: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8618</td>\n",
       "      <td>51.509307</td>\n",
       "      <td>-0.084878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16756</td>\n",
       "      <td>51.383489</td>\n",
       "      <td>-0.105944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38815</td>\n",
       "      <td>51.393451</td>\n",
       "      <td>0.029589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6458</td>\n",
       "      <td>51.573103</td>\n",
       "      <td>-0.212077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38022</td>\n",
       "      <td>51.589213</td>\n",
       "      <td>0.270734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  point_id   latitude  longitude\n",
       "0     8618  51.509307  -0.084878\n",
       "1    16756  51.383489  -0.105944\n",
       "2    38815  51.393451   0.029589\n",
       "3     6458  51.573103  -0.212077\n",
       "4    38022  51.589213   0.270734"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============== READ METADATA (POINTS) ==============\n",
    "meta_fg = fs.get_feature_group(name=METADATA_FG_NAME, version=METADATA_FG_VERSION)\n",
    "points_df = meta_fg.read()\n",
    "\n",
    "needed = [\"point_id\", \"latitude\", \"longitude\"]\n",
    "missing = [c for c in needed if c not in points_df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Metadata FG is missing required columns: {missing}\")\n",
    "\n",
    "points_df = points_df[needed].copy()\n",
    "points_df[\"point_id\"] = points_df[\"point_id\"].astype(str)\n",
    "points_df[\"latitude\"] = pd.to_numeric(points_df[\"latitude\"], errors=\"coerce\")\n",
    "points_df[\"longitude\"] = pd.to_numeric(points_df[\"longitude\"], errors=\"coerce\")\n",
    "points_df = points_df.dropna(subset=[\"latitude\", \"longitude\"]).drop_duplicates(subset=[\"point_id\"], keep=\"last\")\n",
    "\n",
    "print(\"Points available for weather:\", len(points_df))\n",
    "points_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4397a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.00s) \n",
      "Weather backfill date range: 2026-01-04 -> 2026-01-10\n"
     ]
    }
   ],
   "source": [
    "# ============== DETERMINE DATE RANGE ==============\n",
    "def infer_date_range_from_traffic() -> (str, str):\n",
    "    traffic_fg = fs.get_feature_group(name=TRAFFIC_FG_NAME, version=TRAFFIC_FG_VERSION)\n",
    "    tdf = traffic_fg.read()\n",
    "    tdf = tdf[[\"ts_10m\"]]\n",
    "    tdf[\"ts_10m\"] = pd.to_datetime(tdf[\"ts_10m\"], utc=True, errors=\"coerce\")\n",
    "    tdf = tdf.dropna(subset=[\"ts_10m\"])\n",
    "    start = tdf[\"ts_10m\"].min().strftime(\"%Y-%m-%d\")\n",
    "    end = tdf[\"ts_10m\"].max().strftime(\"%Y-%m-%d\")\n",
    "    return start, end\n",
    "\n",
    "if START_DATE and END_DATE:\n",
    "    start_date, end_date = START_DATE, END_DATE\n",
    "else:\n",
    "    start_date, end_date = infer_date_range_from_traffic()\n",
    "\n",
    "print(\"Weather backfill date range:\", start_date, \"->\", end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4f507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== OPEN-METEO FETCH HELPERS ==============\n",
    "def chunk_dataframe(df: pd.DataFrame, chunk_size: int) -> Iterable[pd.DataFrame]:\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        yield df.iloc[i:i + chunk_size]\n",
    "\n",
    "def request_with_retries(url: str, params: Dict[str, Any], timeout: int, max_retries: int) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n",
    "    last_err = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(url, params=params, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            return resp.json()\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            sleep = min(2 ** attempt, 30) + np.random.rand() * 0.5\n",
    "            print(f\"Request failed (attempt {attempt}/{max_retries}). Sleeping {sleep:.1f}s. Error: {e}\")\n",
    "            time.sleep(sleep)\n",
    "    raise RuntimeError(f\"Open-Meteo request failed after {max_retries} retries: {last_err}\")\n",
    "\n",
    "def fetch_open_meteo_archive(lat_list: List[float], lon_list: List[float], start_date: str, end_date: str) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n",
    "    params = {\n",
    "        \"latitude\": \",\".join([str(x) for x in lat_list]),\n",
    "        \"longitude\": \",\".join([str(x) for x in lon_list]),\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": \",\".join(HOURLY_VARS),\n",
    "        \"timezone\": \"UTC\",\n",
    "    }\n",
    "    return request_with_retries(ARCHIVE_URL, params=params, timeout=REQUEST_TIMEOUT, max_retries=MAX_RETRIES)\n",
    "\n",
    "def one_location_to_df(loc_json: Dict[str, Any], point_id: str) -> pd.DataFrame:\n",
    "    if \"hourly\" not in loc_json or \"time\" not in loc_json[\"hourly\"]:\n",
    "        raise ValueError(\"Unexpected Open-Meteo payload format: missing hourly.time\")\n",
    "\n",
    "    times = pd.to_datetime(loc_json[\"hourly\"][\"time\"], utc=True, errors=\"coerce\")\n",
    "    out = pd.DataFrame({\"weather_time_utc\": times, \"point_id\": point_id})\n",
    "\n",
    "    for v in HOURLY_VARS:\n",
    "        out[v] = loc_json[\"hourly\"].get(v, [np.nan] * len(out))\n",
    "\n",
    "    return out\n",
    "\n",
    "def open_meteo_payload_to_df(payload: Union[Dict[str, Any], List[Dict[str, Any]]], point_ids: List[str]) -> pd.DataFrame:\n",
    "    if isinstance(payload, list):\n",
    "        if len(payload) != len(point_ids):\n",
    "            raise ValueError(f\"Payload length {len(payload)} != point_ids length {len(point_ids)}\")\n",
    "        dfs = [one_location_to_df(payload[i], point_ids[i]) for i in range(len(point_ids))]\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return one_location_to_df(payload, point_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a19df9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching chunk 1: n_points=50\n",
      "Fetching chunk 2: n_points=50\n",
      "Fetching chunk 3: n_points=50\n",
      "Fetching chunk 4: n_points=50\n",
      "Weather DF shape: (33600, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_time_utc</th>\n",
       "      <th>point_id</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>2026-01-04 00:00:00+00:00</td>\n",
       "      <td>16108</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>2026-01-04 01:00:00+00:00</td>\n",
       "      <td>16108</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>2026-01-04 02:00:00+00:00</td>\n",
       "      <td>16108</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>2026-01-04 03:00:00+00:00</td>\n",
       "      <td>16108</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8068</th>\n",
       "      <td>2026-01-04 04:00:00+00:00</td>\n",
       "      <td>16108</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              weather_time_utc point_id  temperature_2m  precipitation  rain  snowfall\n",
       "8064 2026-01-04 00:00:00+00:00    16108            -1.5            0.0   0.0       0.0\n",
       "8065 2026-01-04 01:00:00+00:00    16108            -1.6            0.0   0.0       0.0\n",
       "8066 2026-01-04 02:00:00+00:00    16108            -1.8            0.0   0.0       0.0\n",
       "8067 2026-01-04 03:00:00+00:00    16108            -1.9            0.0   0.0       0.0\n",
       "8068 2026-01-04 04:00:00+00:00    16108            -2.0            0.0   0.0       0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============== BACKFILL WEATHER (BATCH) ==============\n",
    "weather_frames = []\n",
    "\n",
    "for idx, chunk in enumerate(chunk_dataframe(points_df, CHUNK_SIZE), start=1):\n",
    "    point_ids = chunk[\"point_id\"].tolist()\n",
    "    lat_list = chunk[\"latitude\"].astype(float).tolist()\n",
    "    lon_list = chunk[\"longitude\"].astype(float).tolist()\n",
    "\n",
    "    print(f\"Fetching chunk {idx}: n_points={len(point_ids)}\")\n",
    "    payload = fetch_open_meteo_archive(lat_list, lon_list, start_date, end_date)\n",
    "    wdf = open_meteo_payload_to_df(payload, point_ids)\n",
    "\n",
    "    weather_frames.append(wdf)\n",
    "    time.sleep(SLEEP_SECONDS)\n",
    "\n",
    "weather_df = pd.concat(weather_frames, ignore_index=True)\n",
    "\n",
    "weather_df[\"point_id\"] = weather_df[\"point_id\"].astype(str)\n",
    "weather_df[\"weather_time_utc\"] = pd.to_datetime(weather_df[\"weather_time_utc\"], utc=True, errors=\"coerce\")\n",
    "weather_df = weather_df.dropna(subset=[\"weather_time_utc\"])\n",
    "\n",
    "weather_df = weather_df.sort_values([\"point_id\", \"weather_time_utc\"])\n",
    "weather_df = weather_df.drop_duplicates(subset=[\"point_id\", \"weather_time_utc\"], keep=\"last\")\n",
    "\n",
    "print(\"Weather DF shape:\", weather_df.shape)\n",
    "weather_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "020e47cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate PK rows: 0\n",
      "NA fraction per hourly variable:\n",
      "temperature_2m    0.0\n",
      "precipitation     0.0\n",
      "rain              0.0\n",
      "snowfall          0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============== QUALITY CHECKS ==============\n",
    "dup = weather_df.duplicated(subset=[\"point_id\", \"weather_time_utc\"]).sum()\n",
    "print(\"Duplicate PK rows:\", dup)\n",
    "if dup > 0:\n",
    "    raise ValueError(\"Primary key duplicates detected in weather_df\")\n",
    "\n",
    "na_report = weather_df[HOURLY_VARS].isna().mean().sort_values(ascending=False)\n",
    "print(\"NA fraction per hourly variable:\")\n",
    "print(na_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01a99251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 33600/33600 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_hourly_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://eu-west.cloud.hopsworks.ai:443/p/3209/jobs/named/weather_hourly_fg_1_offline_fg_materialization/executions\n",
      "Weather backfill written to weather_hourly_fg v1\n"
     ]
    }
   ],
   "source": [
    "# ============== WRITE WEATHER FEATURE GROUP ==============\n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name=WEATHER_FG_NAME,\n",
    "    version=WEATHER_FG_VERSION,\n",
    "    primary_key=[\"point_id\", \"weather_time_utc\"],\n",
    "    event_time=\"weather_time_utc\",\n",
    "    description=\"Hourly weather features from Open-Meteo Historical Weather API (backfilled).\"\n",
    ")\n",
    "\n",
    "weather_fg.insert(\n",
    "    weather_df\n",
    ")\n",
    "\n",
    "print(f\"Weather backfill written to {WEATHER_FG_NAME} v{WEATHER_FG_VERSION}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af34906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/processed/weather_hourly_backfill.parquet rows: 33600\n"
     ]
    }
   ],
   "source": [
    "# ============== OPTIONAL: SAVE LOCAL PARQUET FOR DEBUGGING ==============\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"data/processed/weather_hourly_backfill.parquet\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "weather_df.to_parquet(out_path, index=False)\n",
    "print(\"Saved:\", out_path, \"rows:\", len(weather_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a964fd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 33600\n",
      "unique points: 200\n",
      "unique hours: 168\n",
      "rows / points: 168.0\n",
      "approx days: 7.0\n"
     ]
    }
   ],
   "source": [
    "n_rows = len(weather_df)\n",
    "n_points = weather_df[\"point_id\"].nunique()\n",
    "n_hours = weather_df[\"weather_time_utc\"].nunique()\n",
    "\n",
    "print(\"rows:\", n_rows)\n",
    "print(\"unique points:\", n_points)\n",
    "print(\"unique hours:\", n_hours)\n",
    "\n",
    "print(\"rows / points:\", n_rows / max(n_points, 1))\n",
    "print(\"approx days:\", (n_rows / max(n_points, 1)) / 24)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
