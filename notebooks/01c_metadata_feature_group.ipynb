{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866479eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "952a8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata rows: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>local_authority_id</th>\n",
       "      <th>road_category</th>\n",
       "      <th>road_type</th>\n",
       "      <th>road_name</th>\n",
       "      <th>link_length_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18526</td>\n",
       "      <td>51.529441</td>\n",
       "      <td>0.088977</td>\n",
       "      <td>168</td>\n",
       "      <td>PA</td>\n",
       "      <td>Major</td>\n",
       "      <td>A13</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7518</td>\n",
       "      <td>51.544222</td>\n",
       "      <td>0.147921</td>\n",
       "      <td>168</td>\n",
       "      <td>PA</td>\n",
       "      <td>Major</td>\n",
       "      <td>A1240</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6797</td>\n",
       "      <td>51.367362</td>\n",
       "      <td>0.045676</td>\n",
       "      <td>176</td>\n",
       "      <td>PA</td>\n",
       "      <td>Major</td>\n",
       "      <td>A232</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36807</td>\n",
       "      <td>51.482110</td>\n",
       "      <td>0.101649</td>\n",
       "      <td>105</td>\n",
       "      <td>PA</td>\n",
       "      <td>Major</td>\n",
       "      <td>A209</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28510</td>\n",
       "      <td>51.501415</td>\n",
       "      <td>-0.075800</td>\n",
       "      <td>103</td>\n",
       "      <td>PA</td>\n",
       "      <td>Major</td>\n",
       "      <td>A200</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  point_id   latitude  longitude  local_authority_id road_category road_type  \\\n",
       "0    18526  51.529441   0.088977                 168            PA     Major   \n",
       "1     7518  51.544222   0.147921                 168            PA     Major   \n",
       "2     6797  51.367362   0.045676                 176            PA     Major   \n",
       "3    36807  51.482110   0.101649                 105            PA     Major   \n",
       "4    28510  51.501415  -0.075800                 103            PA     Major   \n",
       "\n",
       "  road_name  link_length_km  \n",
       "0       A13             2.1  \n",
       "1     A1240             2.8  \n",
       "2      A232             1.0  \n",
       "3      A209             1.6  \n",
       "4      A200             0.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-07 22:05:02,690 INFO: Closing external client and cleaning up certificates.\n",
      "2026-01-07 22:05:02,694 INFO: Connection closed.\n",
      "2026-01-07 22:05:02,696 INFO: Initializing external client\n",
      "2026-01-07 22:05:02,696 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-07 22:05:03,295 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/3209\n",
      "Feature Group created: traffic_points_metadata v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 200/200 | Elapsed Time: 00:00 | Remaining Time: 00:00\n",
      "UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://eu-west.cloud.hopsworks.ai:443/p/3209/jobs/named/traffic_points_metadata_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/London_traffic/Resources/jobs/traffic_points_metadata_1_offline_fg_materialization/config_1767819827809) to trigger the materialization job again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('traffic_points_metadata_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load CSV\n",
    "# ----------------------------\n",
    "CSV_PATH = \"data/interim/monitoring_points_metadata.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Basic required columns\n",
    "required = {\"point_id\", \"latitude\", \"longitude\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in CSV: {missing}\")\n",
    "\n",
    "# Clean + types\n",
    "df[\"point_id\"] = df[\"point_id\"].astype(str)\n",
    "df[\"latitude\"] = df[\"latitude\"].astype(float)\n",
    "df[\"longitude\"] = df[\"longitude\"].astype(float)\n",
    "\n",
    "# Optional: keep only a curated set if you want\n",
    "# (comment out if you prefer to keep all columns in the CSV)\n",
    "curated_cols = [\n",
    "    \"point_id\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"local_authority_id\",\n",
    "    \"road_category\",\n",
    "    \"road_type\",\n",
    "    \"region_id\",\n",
    "    \"road_name\",\n",
    "    \"link_length_km\",\n",
    "]\n",
    "curated_cols = [c for c in curated_cols if c in df.columns]\n",
    "df = df[curated_cols].copy()\n",
    "\n",
    "# Validations\n",
    "if df[[\"point_id\", \"latitude\", \"longitude\"]].isna().any().any():\n",
    "    raise ValueError(\"Nulls found in required columns (point_id, latitude, longitude).\")\n",
    "\n",
    "if df[\"point_id\"].duplicated().any():\n",
    "    dupes = df[df[\"point_id\"].duplicated(keep=False)].sort_values(\"point_id\")\n",
    "    raise ValueError(f\"Duplicated point_id found. Example rows:\\n{dupes.head(10)}\")\n",
    "\n",
    "if not df[\"latitude\"].between(-90, 90).all():\n",
    "    raise ValueError(\"Latitude out of range [-90, 90].\")\n",
    "\n",
    "if not df[\"longitude\"].between(-180, 180).all():\n",
    "    raise ValueError(\"Longitude out of range [-180, 180].\")\n",
    "\n",
    "print(\"Loaded metadata rows:\", len(df))\n",
    "display(df.head())\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Login to Hopsworks\n",
    "# ----------------------------\n",
    "\n",
    "# 1. Login to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    host=\"eu-west.cloud.hopsworks.ai\",\n",
    "    project=\"London_traffic\"\n",
    ")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Create / Get Feature Group\n",
    "# ----------------------------\n",
    "FG_NAME = \"traffic_points_metadata\"\n",
    "FG_VERSION = 1\n",
    "FG_DESCRIPTION = \"Static metadata for traffic monitoring points (lat/lon + road/LA context).\"\n",
    "\n",
    "primary_key = [\"point_id\"]\n",
    "\n",
    "fg = fs.get_or_create_feature_group(\n",
    "        name=FG_NAME,\n",
    "        version=FG_VERSION,\n",
    "        description=FG_DESCRIPTION,\n",
    "        primary_key=primary_key\n",
    "    )\n",
    "print(f\"Feature Group created: {FG_NAME} v{FG_VERSION}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Insert (overwrite)\n",
    "# ----------------------------\n",
    "# overwrite=True is ideal for static metadata (idempotent runs)\n",
    "fg.insert(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
